"""
Assignment #4 - Malla Salonen

Generate a command line utility program, which feeds the input of one or multiple sources to LLM. The sources you must support, include text file, URL (html page), csv file, docx file and pdf file.  You can support more input format if you want. User should be able to provide multiple inputs e.g. local text file and web page, or multiple pdf documents. By default, if user has not given the query string, the program will perform summarize, but the user can change the query prompt. By default the output should be printed to standard output, but it should be able to direct it to a file as well.

I recommend to use markitdown or embedchain (for different inputs) and optparse or argparse (to handle command line arguments).
"""

from markitdown import MarkItDown
import argparse
from openai import OpenAI

# Configure OpenAI (using LM Studio API)
client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")  # Connect to the local OpenAI endpoint
model = "gemma-3-12b-it"  # Specify the language model to use


def summarize_file(filepath, client, model, query_prompt=None):
    """
    Summarizes a single file using MarkItDown and OpenAI.

    Args:
        filepath (str): The path to the file to be summarized.
        client (OpenAI): The OpenAI client object for interacting with the LLM.
        model (str): The name of the language model to use.
        query_prompt(str, optional) : Prompt provided by user. if none, perform summarization

    Returns:
        str: The summary generated by the language model, or None if an error occurred.
    """
    md = MarkItDown(llm_client=client, llm_model=model)  # Initialize MarkItDown with the LLM client and model

    try:
        text = md.convert(filepath).text_content  # Convert the file content to plain text

        if query_prompt:
            system_prompt = f"Answer the following question based on this context: {query_prompt}. Context:{text}"
        else:
            system_prompt = "Don't use a preamble. Write a short summary of the text."  # Define system prompt for LLM - sets behavior

        story = [{"role": "system", "content": system_prompt},
                 {"role": "user", "content": text}] # Create messages array to send to the llm including system and user instructions

        summary_response = client.chat.completions.create(  # Send prompt to LLM for summarization
            model=model,  # Specify model
            messages=story,    # Pass the instruction to LLM
            temperature=0.7,     # Set temperature (higher is more creative)
            stream=False,   # Get response not streamed
            top_p=0.7,       # Nucleus sampling parameter
            presence_penalty=1.0, # Penalize new topics
            frequency_penalty=1.0,  # Penalize repeated tokens
            max_tokens=500    # Limit the maximum length of the response
        )

        # role assistant gives the answer from the model
        return summary_response.choices[0].message.content  # Extract the summary content from the LLM's response

    except Exception as e:
        print(f"Error summarizing {filepath}: {e}") # Print error messages for debugging
        return None



def main():
    """
    Gets file paths from user input and summarizes them.
    Handles user interaction to get file inputs, then calls summarize_file() for each.
    Prints results or error messages.  Asks the user if they want a query prompt.
    """

    files = []  # Initialize an empty list to store the entered files.
    
    print("\n")

    while True:
        file_path = input("Enter a file you want to summarize (or type 'done' to finish): ") # Prompt user for a filepath
        if file_path.lower() == "done" or file_path == "":  # Check if the user wants to stop entering files
            break   # Exit loop when done is entered
        files.append(file_path) # add filepath into list of files

    if not files:  # If no files were provided, exit.
        print("No files provided.")
        return  # Exit the program.

    prompt = input("\nEnter a query prompt (or leave blank for summarization): ")  # Ask if user wants to add a prompt

    print ("\nI'm summarizing the files... Please, be patient...\n") # Status Message to let user know what is happening in background.
    summaries = []  # Initialize an empty list to store successful summaries
    for filepath in files:  # Iterate over each file path entered by the user
        summary = summarize_file(filepath, client, model, prompt) # Call summarize_file and save results
        if summary: # Check if summarizing was successfull
            summaries.append(summary) # add the successful summaries to list of summaries
        else:
            print("Could not summarize ", filepath)   # Print a message if summarization failed            

    print ("\n--- Summarized",  len(summaries), "files out of", len(files), "files. ---\n") # summary statistics

    # Print the summaries to screen
    if summaries:
        for i, summary in enumerate(summaries): # Iterate through each successfully generated summary
            if len(prompt) == 0: # user provided a prompt
                print(f"Summary {i+1}:\n")  # Print number of summary to identify
            print (summary,"\n")
    else:
        print("No files were successfully summarized.")  # Notify the user if no summaries were produced


    # Ask if the user wants to save the summaries to a file only if there are summaries to save
    if summaries:
        print ("Do you want some of the summaries saved to a file? (y/n)")
        save = input("Enter y or n: ") # Ask if user wants to save summaries to file
    
        if save.lower() == "y":  # Check if the user wants to save the summaries
            filename = input("Enter the filename to save the summaries: ")  # Prompt for the filename
            try:
                with open(filename, "w", encoding="utf-8") as f:  # Open the file for writing
                    for i, summary in enumerate(summaries):  # Iterate over each summary
                        f.write(f"Summary {i+1}:\n{summary}\n\n")  # Write each summary to the file
                print(f"Summaries saved to {filename}")  # Notify the user of successful saving
            except Exception as e:
                print(f"Error saving summaries: {e}")  # Print error message if saving fails    

if __name__ == "__main__":
    main()  # This line ensures that the main function is executed only when the script is run directly (not imported as a module)
